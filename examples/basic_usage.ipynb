{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basic Usage\n",
    "This notebook illustrates the basic usage to create incremental explanations with our incremental explainers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Modules\n",
    "Imports all necessary modules at once."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from river.metrics import CrossEntropy, Accuracy\n",
    "from river.utils import Rolling\n",
    "from river.ensemble import AdaptiveRandomForestClassifier\n",
    "\n",
    "from river.datasets.synth import Agrawal\n",
    "\n",
    "from increment_explain.explainer import IncrementalPFI\n",
    "from increment_explain.explainer.sage import IncrementalSage, IntervalSage\n",
    "from increment_explain.imputer import MarginalImputer\n",
    "from increment_explain.storage import GeometricReservoirStorage\n",
    "from increment_explain.utils.wrappers.river import RiverPredictionFunctionWrapper\n",
    "from increment_explain.visualization import FeatureImportancePlotter"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup data stream"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stream = Agrawal(classification_function=1, seed=42)\n",
    "feature_names = list([x_0 for x_0, _ in stream.take(1)][0].keys())\n",
    "n_samples = 25_000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup model and loss function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AdaptiveRandomForestClassifier(n_models=15, max_depth=10, leaf_prediction='mc')\n",
    "model_function = RiverPredictionFunctionWrapper(model.predict_proba_one)\n",
    "\n",
    "loss_metric = CrossEntropy()\n",
    "training_metric = Rolling(CrossEntropy(), window_size=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup Explainers\n",
    "The explainer also require an imputer and a storage mechanism."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "storage = GeometricReservoirStorage(\n",
    "    size=200,\n",
    "    store_targets=False\n",
    ")\n",
    "\n",
    "imputer = MarginalImputer(\n",
    "    model_function=model_function,\n",
    "    storage_object=storage,\n",
    "    sampling_strategy=\"joint\"\n",
    ")\n",
    "\n",
    "incremental_sage = IncrementalSage(\n",
    "    model_function=model_function,\n",
    "    loss_function=loss_metric,\n",
    "    imputer=imputer,\n",
    "    storage=storage,\n",
    "    feature_names=feature_names,\n",
    "    smoothing_alpha=0.001,\n",
    "    n_inner_samples=1\n",
    ")\n",
    "\n",
    "interval_sage = IntervalSage(\n",
    "    model_function=model_function,\n",
    "    loss_function=loss_metric,\n",
    "    feature_names=feature_names,\n",
    "    interval_length=2000,\n",
    "    n_inner_samples=1\n",
    ")\n",
    "\n",
    "incremental_pfi = IncrementalPFI(\n",
    "    model_function=model_function,\n",
    "    loss_function=loss_metric,\n",
    "    imputer=imputer,\n",
    "    storage=storage,\n",
    "    feature_names=feature_names,\n",
    "    smoothing_alpha=0.001,\n",
    "    n_inner_samples=1\n",
    ")\n",
    "\n",
    "sage_plotter = FeatureImportancePlotter(feature_names=feature_names)\n",
    "pfi_plotter = FeatureImportancePlotter(feature_names=feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and explain the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for (n, (x_i, y_i)) in enumerate(stream, start=1):\n",
    "    # predicting\n",
    "    y_i_pred = model.predict_proba_one(x_i)\n",
    "    training_metric.update(y_true=y_i, y_pred=y_i_pred)\n",
    "\n",
    "    # sage inc\n",
    "    inc_fi_sage = incremental_sage.explain_one(x_i, y_i)\n",
    "    int_fi_sage = interval_sage.explain_one(x_i, y_i)\n",
    "    inc_fi_pfi = incremental_pfi.explain_one(x_i, y_i, update_storage=False)\n",
    "\n",
    "    # visualize\n",
    "    sage_plotter.update(inc_fi_sage, facet_name='inc-sage')\n",
    "    sage_plotter.update(int_fi_sage, facet_name='int-sage')\n",
    "    pfi_plotter.update(inc_fi_pfi, facet_name='inc-pfi')\n",
    "\n",
    "    # learning\n",
    "    model.learn_one(x_i, y_i)\n",
    "\n",
    "    if n % 1000 == 0:\n",
    "        print(f\"{n}: perf                {training_metric.get()}\\n\"\n",
    "              f\"{n}: x_i                 {x_i}\\n\"\n",
    "              f\"{n}: inc-sage            {incremental_sage.importance_values}\\n\"\n",
    "              f\"{n}: int-sage            {interval_sage.importance_values}\\n\"\n",
    "              f\"{n}: pfi-sage            {incremental_pfi.importance_values}\\n\"\n",
    "              f\"{n}: diff                {incremental_sage.marginal_loss - incremental_sage.model_loss}\\n\"\n",
    "              f\"{n}: marginal-loss       {incremental_sage.marginal_loss}\\n\"\n",
    "              f\"{n}: model-loss          {incremental_sage.model_loss}\\n\"\n",
    "              f\"{n}: sum-sage            {sum(list(incremental_sage.importance_values.values()))}\\n\")\n",
    "\n",
    "    if n >= n_samples:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO add plotter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}